{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Untitled (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IndraP24/MyCaptain-Codes/blob/master/Test%20Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMLcCTJ_GoPh",
        "colab_type": "code",
        "colab": {},
        "outputId": "dcb702e5-e7e2-419b-cfee-e2bb36986fae"
      },
      "source": [
        "#importing dependencies\n",
        "import numpy as np\n",
        "import sys\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaVRJCVNGoPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load data\n",
        "#loading data and opening our input data in the form of a txt file\n",
        "#Project Gutenberg is where the data can be found\n",
        "file = open(\"84-0.txt\").read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrjFtmVkGoPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenization\n",
        "#standardization\n",
        "def tokenize_words(input):\n",
        "  #lowercase everything to standardize it\n",
        "  input = input.lower()\n",
        "  #instantiating the tokenizer\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  #tokenizing the text into tokens\n",
        "  tokens = tokenizer.tokenize(input)\n",
        "  #filtering the stopwords using lambda\n",
        "  filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
        "  return \"\".join(filtered)\n",
        "\n",
        "#preprocess the input data, make tokens\n",
        "processed_inputs = tokenize_words(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbOO4Mk_GoPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#chars to numbers\n",
        "chars = sorted(list(set(processed_inputs)))\n",
        "char_to_num = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9Pm509NGoPt",
        "colab_type": "code",
        "colab": {},
        "outputId": "58350d23-e4e2-4ea4-c91d-1ca24e5f4edd"
      },
      "source": [
        "#check if words to chars or chars to num (?!) has worked\n",
        "input_len = len(processed_inputs)\n",
        "vocab_len = len(chars)\n",
        "print('Total No. of Characters: ', input_len)\n",
        "print('Total vocab: ', vocab_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total No. of Characters:  233296\n",
            "Total vocab:  42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGGGn7MHGoPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#seq length\n",
        "seq_length = 100\n",
        "x_data = []\n",
        "y_data = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQhlGwsOGoPy",
        "colab_type": "code",
        "colab": {},
        "outputId": "62eee659-2729-4865-e293-8cd5150bc710"
      },
      "source": [
        "#loop through the sequence\n",
        "for i in range(0, input_len - seq_length, 1):\n",
        "  in_seq = processed_inputs[i:i + seq_length]\n",
        "  out_seq = processed_inputs[i + seq_length]\n",
        "  x_data.append([char_to_num[char] for char in in_seq])\n",
        "  y_data.append(char_to_num[out_seq])\n",
        "\n",
        "n_patterns = len(x_data)\n",
        "print('Total Patterns:', n_patterns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns: 233196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nuBSQAKGoP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert input sequence to np array that our network can use\n",
        "x = np.reshape(x_data, (n_patterns, seq_length, 1))\n",
        "x = x / float(vocab_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPBTO1prGoP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#one hot encoding our label data\n",
        "y = np_utils.to_categorical(y_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77jsdT0HGoP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating the sequential model\n",
        "#dropout is uesd to predict\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape = (x.shape[1], x.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgAmUZh6GoP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile the model\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YINDJh0DGoP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saving weights\n",
        "filepath = 'model_weights_saved.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor = 'loss', verbose = 1, save_best_only=True, mode = 'min')\n",
        "desired_callbacks = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq8W3F5UGoP_",
        "colab_type": "code",
        "colab": {},
        "outputId": "e6f3403e-3943-4f81-ca2d-457c7cf97930"
      },
      "source": [
        "model.fit(x, y, epochs = 4, batch_size=256, callbacks=desired_callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "233196/233196 [==============================] - 569s 2ms/step - loss: 2.9310\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.93103, saving model to model_weights_saved.hdf5\n",
            "Epoch 2/4\n",
            "233196/233196 [==============================] - 567s 2ms/step - loss: 2.9105\n",
            "\n",
            "Epoch 00002: loss improved from 2.93103 to 2.91045, saving model to model_weights_saved.hdf5\n",
            "Epoch 3/4\n",
            "233196/233196 [==============================] - 565s 2ms/step - loss: 2.8680\n",
            "\n",
            "Epoch 00003: loss improved from 2.91045 to 2.86804, saving model to model_weights_saved.hdf5\n",
            "Epoch 4/4\n",
            "233196/233196 [==============================] - 565s 2ms/step - loss: 2.8000\n",
            "\n",
            "Epoch 00004: loss improved from 2.86804 to 2.79997, saving model to model_weights_saved.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f62c184bb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiGGAB4eGoQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recompile model with the saved weights\n",
        "filename = \"model_weights_saved.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GUteGd6GoQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#output of the model back into characters\n",
        "num_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0cNTQG6GoQG",
        "colab_type": "code",
        "colab": {},
        "outputId": "c61ebcdb-cefc-455e-ea69-9ea23601cce7"
      },
      "source": [
        "#random seed to help generate\n",
        "start = np.random.randint(0, len(x_data) - 1)\n",
        "pattern = x_data[start]\n",
        "print(\"Random Seed:\")\n",
        "print(\"\\\"\", ''.join([num_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed:\n",
            "\" etseashoreinquiredinhabitantsconcerningfiendgainedaccurateinformationgiganticmonstersaidarrivednight \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff5JqVHXGoQJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "03b0b924-69d9-44b8-a4a0-a938301b8c4b"
      },
      "source": [
        "#generate the text\n",
        "for i in range(1000):\n",
        "  x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "  x = x / float(vocab_len)\n",
        "  prediction = model.predict(x, verbose = 0)\n",
        "  index = np.argmax(prediction)\n",
        "  result = num_to_char[index]\n",
        "  seq_in = [num_to_char[value] for value in pattern]\n",
        "  sys.stdout.write(result)\n",
        "  pattern.append(index)\n",
        "  pattern = pattern[1:len(pattern)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ereeredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredredred"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAWKabW6GoQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}